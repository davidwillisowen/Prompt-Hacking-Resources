# BLOGS

• [AIBlade](https://www.aiblade.net/) – Curated directory of AI red teaming tools and resources  
• [EmbraceTheRed](https://embracethered.com/blog/) – Practical experiments and insights from active AI red teamers  
• [Joseph Thacker](https://josephthacker.com/) – First-person red teaming explorations and LLM vulnerability research  
• [LearnPrompting Prompt Hacking](https://learnprompting.org/docs/prompt_hacking/introduction) – Step-by-step educational guide to prompt injection and model exploitation  
• [Protect AI Blog](https://protectai.com/blog) – Enterprise-grade AI security insights and open-source tooling announcements  
• [AWS Generative AI Security](https://aws.amazon.com/blogs/security/category/artificial-intelligence/generative-ai/) – Secure architecture and compliance guidance for GenAI workloads  
• [Lakera AI Blog](https://www.lakera.ai/blog) – Interactive red teaming campaigns and accessible safety content (e.g., Gandalf)  
• [Securiti AI Security](https://securiti.ai/blog/) – Governance, risk, and compliance content for data-centric AI security  
• [PurpleSec AI & ML Security](https://purplesec.us/learn/ai-security/) – Broad cybersecurity context applied to AI/ML threat models  
• [Wiz AI Security Articles](https://www.wiz.io/blog/top-10-ai-security-articles) – Curated executive-level insights on AI risk and security trends  
• [Lasso Security Blog](https://www.lasso.security/blog) – Offensive research into prompt injection, training set leaks, and adversarial LLM behavior  
• [Cisco AI Safety](https://blogs.cisco.com/news/you-cant-sacrifice-ai-safety-for-ai-speed) – Strategic perspective on embedding AI safety into innovation cycles  
• [Microsoft Security: AI & ML](https://www.microsoft.com/en-us/security/blog/topic/ai-and-machine-learning/) – Deep dives into red teaming, threat modeling, and Responsible AI practices  
• [Vectra AI Cybersecurity Blog](https://www.vectra.ai/blog) – Using AI to defend against AI-driven threats in enterprise security
